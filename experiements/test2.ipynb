{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "os.chdir(\"..\")\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二个实验测试\n",
    "# 我已经选择了合适的学习率, 打算跑1000次然后记录图片并且查看相应的降噪成果, 没啥东西就用这个跑\n",
    "# 模型相关\n",
    "import torch\n",
    "from models.DIP_2D import DIP_2D\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "# 画图相关\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 文件读写相关\n",
    "import csv\n",
    "from config.config import *\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# 自定义函数\n",
    "from utils.pre_utils import *\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = \"data/noisy_images/uniform_noise.npy\"\n",
    "path_ground_truth = \"data/ground_truth/ground_truth.npy\"\n",
    "path_target = \"data/corrupted_images/BSREM_it30.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_input = np.load(path_input)\n",
    "\n",
    "# image_net_input_scale,param1_scale_im_net,param2_scale_im_net = rescale_imag(image_net_input,\"standardization\") \n",
    "# image_net_input_torch = torch.Tensor(image_net_input_scale)\n",
    "\n",
    "image_net_input_torch = torch.Tensor(image_net_input)\n",
    "image_net_input_torch = image_net_input_torch.view(1,1,PETImage_shape[0],PETImage_shape[1],PETImage_shape[2])\n",
    "image_net_input_torch = image_net_input_torch[:,:,:,:,0]\n",
    "\n",
    "ground_truth = np.load(path_ground_truth)\n",
    "\n",
    "image_corrupt = np.load(path_target)\n",
    "image_corrupt_input_scaled,param1_scale_im_corrupt,param2_scale_im_corrupt = rescale_imag(image_corrupt,\"standardization\") # 标准化图片, 减去平均值，除以标准差，参数1是mean，参数2是std\n",
    "image_corrupt_torch = torch.Tensor(image_corrupt_input_scaled)\n",
    "image_corrupt_torch = image_corrupt_torch.view(1,1,PETImage_shape[0],PETImage_shape[1],PETImage_shape[2])\n",
    "image_corrupt_torch = image_corrupt_torch[:,:,:,:,0]\n",
    "\n",
    "plt.imshow(ground_truth, cmap='gray')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # 加载数据\n",
    "train_dataset = torch.utils.data.TensorDataset(image_net_input_torch,image_corrupt_torch)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n",
    "\n",
    "# 加载模型\n",
    "model = DIP_2D(param1_scale_im_corrupt, param2_scale_im_corrupt, config,'data/Algo/',\n",
    "            \"nested\",all_images_DIP=\"False\",global_it=-100, suffix='aaa',last_iter=-1,ground_truth=ground_truth,target=image_corrupt,initial_param='kaiming_norm')\n",
    "# model.init_weights()\n",
    "model_class = DIP_2D\n",
    "\n",
    "#定义tensorboard\n",
    "checkpoint_simple_path = os.getcwd() + '/test2_logs'\n",
    "# experiment = 24\n",
    "name=str(datetime.datetime.now())\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=checkpoint_simple_path,name=name)#version=format(experiment), name=name)\n",
    "trainer = pl.Trainer(max_epochs=config[\"sub_iter_DIP\"],log_every_n_steps=1,logger=logger)#, callbacks=[checkpoint_callback, tuning_callback, early_stopping_callback], logger=logger,gpus=gpus, accelerator=accelerator, profiler=\"simple\")\n",
    "\n",
    "# 训练模型\n",
    "trainer.fit(model, train_dataloader)\n",
    "out = model(image_net_input_torch)\n",
    "\n",
    "image_out = out.view(PETImage_shape[0],PETImage_shape[1],PETImage_shape[2]).detach().numpy()\n",
    "image_concat = np.concatenate((image_corrupt, destand_numpy_imag(image_out,param1_scale_im_corrupt,param2_scale_im_corrupt)), axis=1)\n",
    "image_reversed =np.max(image_concat)-image_concat\n",
    "\n",
    "plt.imshow(image_reversed, cmap='gray')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xzhang/miniconda3/envs/dip/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/xzhang/miniconda3/envs/dip/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/xzhang/miniconda3/envs/dip/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1292: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "   | Name       | Type       | Params\n",
      "-------------------------------------------\n",
      "0  | deep1      | Sequential | 2.5 K \n",
      "1  | down1      | Sequential | 2.4 K \n",
      "2  | deep2      | Sequential | 14.0 K\n",
      "3  | down2      | Sequential | 9.3 K \n",
      "4  | deep3      | Sequential | 55.7 K\n",
      "5  | down3      | Sequential | 37.1 K\n",
      "6  | deep4      | Sequential | 221 K \n",
      "7  | up1        | Sequential | 73.9 K\n",
      "8  | deep5      | Sequential | 74.1 K\n",
      "9  | up2        | Sequential | 18.5 K\n",
      "10 | deep6      | Sequential | 18.6 K\n",
      "11 | up3        | Sequential | 4.7 K \n",
      "12 | deep7      | Sequential | 2.5 K \n",
      "13 | positivity | ReLU       | 0     \n",
      "-------------------------------------------\n",
      "535 K     Trainable params\n",
      "0         Non-trainable params\n",
      "535 K     Total params\n",
      "2.141     Total estimated model params size (MB)\n",
      "/home/xzhang/miniconda3/envs/dip/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xzhang/Documents/我的模型/experiments\n",
      "current working directory switched to /home/xzhang/Documents/我的模型\n",
      "staaaaaaaaaaand\n",
      "Number of params: 535251\n",
      "Epoch 39:   0%|          | 0/1 [00:00<00:00, 980.66it/s, loss=0.166, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_39.img\n",
      "Epoch 79:   0%|          | 0/1 [00:00<00:00, 671.30it/s, loss=0.0997, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_79.img\n",
      "Epoch 119:   0%|          | 0/1 [00:00<00:00, 704.21it/s, loss=0.08, v_num=0]    0\n",
      "Succesfully save in: data/output_images/output_aaa_119.img\n",
      "Epoch 159:   0%|          | 0/1 [00:00<00:00, 693.85it/s, loss=0.0612, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_159.img\n",
      "Epoch 199:   0%|          | 0/1 [00:00<00:00, 909.63it/s, loss=0.0494, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_199.img\n",
      "Epoch 239:   0%|          | 0/1 [00:00<00:00, 924.06it/s, loss=0.0389, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_239.img\n",
      "Epoch 279:   0%|          | 0/1 [00:00<00:00, 635.50it/s, loss=0.0287, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_279.img\n",
      "Epoch 319:   0%|          | 0/1 [00:00<00:00, 732.12it/s, loss=0.0195, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_319.img\n",
      "Epoch 359:   0%|          | 0/1 [00:00<00:00, 768.19it/s, loss=0.0147, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_359.img\n",
      "Epoch 399:   0%|          | 0/1 [00:00<00:00, 790.04it/s, loss=0.0108, v_num=0]  0\n",
      "Succesfully save in: data/output_images/output_aaa_399.img\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s, loss=0.0108, v_num=0] \n"
     ]
    }
   ],
   "source": [
    "from test import *\n",
    "\n",
    "psnr_list,mse_gt_list = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/results/statistics/' + str(datetime.datetime.now()).split(' ')[0] +'.csv'\n",
    "save_csv(filename,psnr_list,mse_gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iters       psnr       mse_gt\n",
      "0      0  15.545695  4826.700598\n",
      "1      1  15.783134  4404.932145\n",
      "2      2  18.142100  2438.853499\n",
      "3      3  17.514765  2099.006888\n",
      "4      4  15.849874  1903.451395\n",
      "            iters        psnr       mse_gt\n",
      "count  400.000000  400.000000   400.000000\n",
      "mean   199.500000   26.144598   887.303635\n",
      "std    115.614301    1.928070   316.167230\n",
      "min      0.000000   15.545695   574.990220\n",
      "25%     99.750000   26.260973   768.287932\n",
      "50%    199.500000   26.699021   871.519780\n",
      "75%    299.250000   27.027078   962.026121\n",
      "max    399.000000   27.899275  4826.700598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tb = read_csv(filename)\n",
    "# sns.relplot(x=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
