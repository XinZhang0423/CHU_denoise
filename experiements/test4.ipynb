{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用lr = 0.01\n",
    "# 测试xavier_uniform,xavier_norm, kaiming_uniform,kaiming_norm，以及默认的初始化方法 也是一个loop同时还有保存数据部分呢\n",
    "# 将psnr,mse_gt记录下来即可\n",
    "# 各跑100遍\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "os.chdir(\"..\")\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.DIP_2D import DIP_2D\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "# 画图相关\n",
    "import matplotlib.pyplot as plt\n",
    "# 文件读写相关\n",
    "import csv\n",
    "from config.config import *\n",
    "import pandas as pd\n",
    "import csv\n",
    "# 自定义函数\n",
    "from utils.pre_utils import *\n",
    "from functools import partial\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = \"data/noisy_images/uniform_noise3.npy\"\n",
    "path_ground_truth = \"data/ground_truth/ground_truth.npy\"\n",
    "path_target = \"data/corrupted_images/BSREM_it30.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_input = np.load(path_input)\n",
    "\n",
    "# image_net_input_scale,param1_scale_im_net,param2_scale_im_net = rescale_imag(image_net_input,\"standardization\") \n",
    "# image_net_input_torch = torch.Tensor(image_net_input_scale)\n",
    "\n",
    "image_net_input_torch = torch.Tensor(image_net_input)\n",
    "image_net_input_torch = image_net_input_torch.view(1,1,PETImage_shape[0],PETImage_shape[1],PETImage_shape[2])\n",
    "image_net_input_torch = image_net_input_torch[:,:,:,:,0]\n",
    "\n",
    "ground_truth = np.load(path_ground_truth)\n",
    "\n",
    "image_corrupt = np.load(path_target)\n",
    "image_corrupt_input_scaled,param1_scale_im_corrupt,param2_scale_im_corrupt = rescale_imag(image_corrupt,\"standardization\") # 标准化图片, 减去平均值，除以标准差，参数1是mean，参数2是std\n",
    "image_corrupt_torch = torch.Tensor(image_corrupt_input_scaled)\n",
    "image_corrupt_torch = image_corrupt_torch.view(1,1,PETImage_shape[0],PETImage_shape[1],PETImage_shape[2])\n",
    "image_corrupt_torch = image_corrupt_torch[:,:,:,:,0]\n",
    "\n",
    "plt.imshow(ground_truth, cmap='gray')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(my_dict, file_name):\n",
    "    nb_cols = len(list(my_dict.keys()))\n",
    "    nb_rows = len(my_dict[f\"{1}\"])\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # 写入表头\n",
    "        header = ['iters'] + list(range(nb_cols))\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # 写入数据\n",
    "        for i in range(nb_rows):\n",
    "            row = [i] + [my_dict[f\"{j}\"][i] for j in range(nb_cols)]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 到100遍\n",
    "psnr_dict = dict()\n",
    "mse_gt_dict = dict()\n",
    "init_dict = dict()\n",
    "init_method = ['xavier_norm','xavier_uniform','kaiming_norm', 'kaiming_uniform']\n",
    "\n",
    "# for method in init_method:\n",
    "#     for i in range(100):\n",
    "#         # 加载数据\n",
    "#         train_dataset = torch.utils.data.TensorDataset(image_net_input_torch,image_corrupt_torch)\n",
    "#         train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n",
    "#         suffix = f'test4/{method}/train_{i}/iters'\n",
    "#         # 加载模型\n",
    "#         model = DIP_2D(param1_scale_im_corrupt, param2_scale_im_corrupt, config,'data/Algo/',\n",
    "#                     \"nested\",all_images_DIP=\"False\",global_it=-100, suffix=method,last_iter=-1,ground_truth=ground_truth, initial_param=method)\n",
    "#         model.init_weights()\n",
    "#         model_class = DIP_2D\n",
    "\n",
    "#         #定义tensorboard\n",
    "#         checkpoint_simple_path = os.getcwd() + '/logs/test6_logs'\n",
    "#         # experiment = 24\n",
    "#         name=str(datetime.datetime.now())\n",
    "\n",
    "#         logger = pl.loggers.TensorBoardLogger(save_dir=checkpoint_simple_path,name=name)#version=format(experiment), name=name)\n",
    "#         trainer = pl.Trainer(max_epochs=config[\"sub_iter_DIP\"],log_every_n_steps=1,logger=logger)#, callbacks=[checkpoint_callback, tuning_callback, early_stopping_callback], logger=logger,gpus=gpus, accelerator=accelerator, profiler=\"simple\")\n",
    "\n",
    "#         # 训练模型\n",
    "#         trainer.fit(model, train_dataloader)\n",
    "#         out = model(image_net_input_torch)\n",
    "#         psnr_dict[f\"{i}\"] = model.psnr_list \n",
    "#         mse_gt_dict[f\"{i}\"] = model.mse_gt_list\n",
    "        \n",
    "#         image_out = out.view(PETImage_shape[0],PETImage_shape[1],PETImage_shape[2]).detach().numpy()\n",
    "#         image_concat = np.concatenate((image_corrupt, destand_numpy_imag(image_out,param1_scale_im_corrupt,param2_scale_im_corrupt)), axis=1)\n",
    "#         image_reversed = np.max(image_concat)-image_concat\n",
    "        \n",
    "#     init_dict[f\"{method}\"]=psnr_dict,mse_gt_dict  \n",
    "#     write_csv(psnr_dict, file_name=f\"{method}_psnr.csv\")\n",
    "#     write_csv(mse_gt_dict,file_name=f\"{method}_mse_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # 加载数据\n",
    "    train_dataset = torch.utils.data.TensorDataset(image_net_input_torch,image_corrupt_torch)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n",
    "    suffix = f'test4/default/train_{i}/iters'\n",
    "    # 加载模型\n",
    "    model = DIP_2D(param1_scale_im_corrupt, param2_scale_im_corrupt, config,'data/Algo/',\n",
    "                \"nested\",all_images_DIP=\"False\",global_it=-100, suffix=suffix,last_iter=-1,ground_truth=ground_truth, initial_param='default')\n",
    "    #model.init_weights()\n",
    "    model_class = DIP_2D\n",
    "\n",
    "    #定义tensorboard\n",
    "    checkpoint_simple_path = os.getcwd() + '/logs/test6_logs'\n",
    "    # experiment = 24\n",
    "    name=str(datetime.datetime.now())\n",
    "\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=checkpoint_simple_path,name=name)#version=format(experiment), name=name)\n",
    "    trainer = pl.Trainer(max_epochs=config[\"sub_iter_DIP\"],log_every_n_steps=1,logger=logger)#, callbacks=[checkpoint_callback, tuning_callback, early_stopping_callback], logger=logger,gpus=gpus, accelerator=accelerator, profiler=\"simple\")\n",
    "\n",
    "    # 训练模型\n",
    "    trainer.fit(model, train_dataloader)\n",
    "    out = model(image_net_input_torch)\n",
    "    psnr_dict[f\"{i}\"] = model.psnr_list \n",
    "    mse_gt_dict[f\"{i}\"] = model.mse_gt_list\n",
    "    \n",
    "    image_out = out.view(PETImage_shape[0],PETImage_shape[1],PETImage_shape[2]).detach().numpy()\n",
    "    image_concat = np.concatenate((image_corrupt, destand_numpy_imag(image_out,param1_scale_im_corrupt,param2_scale_im_corrupt)), axis=1)\n",
    "    image_reversed = np.max(image_concat)-image_concat\n",
    "    \n",
    "init_dict[\"default\"]=psnr_dict,mse_gt_dict  \n",
    "write_csv(psnr_dict, file_name=\"default_psnr.csv\")\n",
    "write_csv(mse_gt_dict,file_name=\"default_mse_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 到100遍\n",
    "psnr_dict = dict()\n",
    "mse_gt_dict = dict()\n",
    "init_dict = dict()\n",
    "init_method = ['xavier_norm','xavier_uniform','kaiming_norm', 'kaiming_uniform']\n",
    "\n",
    "for method in init_method:\n",
    "    for i in range(100):\n",
    "        # 加载数据\n",
    "        train_dataset = torch.utils.data.TensorDataset(image_net_input_torch,image_corrupt_torch)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n",
    "        suffix = f'test4/{method}/train_{i}/iters'\n",
    "        # 加载模型\n",
    "        model = DIP_2D(param1_scale_im_corrupt, param2_scale_im_corrupt, config,'data/Algo/',\n",
    "                    \"nested\",all_images_DIP=\"False\",global_it=-100, suffix=suffix,last_iter=-1,ground_truth=ground_truth, initial_param=method)\n",
    "        model.init_weights()\n",
    "        model_class = DIP_2D\n",
    "\n",
    "        #定义tensorboard\n",
    "        checkpoint_simple_path = os.getcwd() + '/logs/test6_logs'\n",
    "        # experiment = 24\n",
    "        name=str(datetime.datetime.now())\n",
    "\n",
    "        logger = pl.loggers.TensorBoardLogger(save_dir=checkpoint_simple_path,name=name)#version=format(experiment), name=name)\n",
    "        trainer = pl.Trainer(max_epochs=config[\"sub_iter_DIP\"],log_every_n_steps=1,logger=logger)#, callbacks=[checkpoint_callback, tuning_callback, early_stopping_callback], logger=logger,gpus=gpus, accelerator=accelerator, profiler=\"simple\")\n",
    "\n",
    "        # 训练模型\n",
    "        trainer.fit(model, train_dataloader)\n",
    "        out = model(image_net_input_torch)\n",
    "        psnr_dict[f\"{i}\"] = model.psnr_list \n",
    "        mse_gt_dict[f\"{i}\"] = model.mse_gt_list\n",
    "        \n",
    "        image_out = out.view(PETImage_shape[0],PETImage_shape[1],PETImage_shape[2]).detach().numpy()\n",
    "        image_concat = np.concatenate((image_corrupt, destand_numpy_imag(image_out,param1_scale_im_corrupt,param2_scale_im_corrupt)), axis=1)\n",
    "        image_reversed = np.max(image_concat)-image_concat\n",
    "        \n",
    "    init_dict[f\"{method}\"]=psnr_dict,mse_gt_dict  \n",
    "    write_csv(psnr_dict, file_name=f\"{method}_psnr.csv\")\n",
    "    write_csv(mse_gt_dict,file_name=f\"{method}_mse_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # 加载数据\n",
    "    train_dataset = torch.utils.data.TensorDataset(image_net_input_torch,image_corrupt_torch)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n",
    "    suffix = f'test4/default/train_{i}/iters'\n",
    "    # 加载模型\n",
    "    model = DIP_2D(param1_scale_im_corrupt, param2_scale_im_corrupt, config,'data/Algo/',\n",
    "                \"nested\",all_images_DIP=\"False\",global_it=-100, suffix='default',last_iter=-1,ground_truth=ground_truth, initial_param='default')\n",
    "    #model.init_weights()\n",
    "    model_class = DIP_2D\n",
    "\n",
    "    #定义tensorboard\n",
    "    checkpoint_simple_path = os.getcwd() + '/logs/test6_logs'\n",
    "    # experiment = 24\n",
    "    name=str(datetime.datetime.now())\n",
    "\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=checkpoint_simple_path,name=name)#version=format(experiment), name=name)\n",
    "    trainer = pl.Trainer(max_epochs=config[\"sub_iter_DIP\"],log_every_n_steps=1,logger=logger)#, callbacks=[checkpoint_callback, tuning_callback, early_stopping_callback], logger=logger,gpus=gpus, accelerator=accelerator, profiler=\"simple\")\n",
    "\n",
    "    # 训练模型\n",
    "    trainer.fit(model, train_dataloader)\n",
    "    out = model(image_net_input_torch)\n",
    "    psnr_dict[f\"{i}\"] = model.psnr_list \n",
    "    mse_gt_dict[f\"{i}\"] = model.mse_gt_list\n",
    "    \n",
    "    image_out = out.view(PETImage_shape[0],PETImage_shape[1],PETImage_shape[2]).detach().numpy()\n",
    "    image_concat = np.concatenate((image_corrupt, destand_numpy_imag(image_out,param1_scale_im_corrupt,param2_scale_im_corrupt)), axis=1)\n",
    "    image_reversed = np.max(image_concat)-image_concat\n",
    "    \n",
    "init_dict[\"default\"]=psnr_dict,mse_gt_dict  \n",
    "write_csv(psnr_dict, file_name=\"default_psnr.csv\")\n",
    "write_csv(mse_gt_dict,file_name=\"default_mse_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
